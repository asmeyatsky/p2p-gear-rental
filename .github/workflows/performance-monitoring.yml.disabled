name: Performance Monitoring

on:
  schedule:
    - cron: '0 */6 * * *' # Every 6 hours
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'package*.json'
  workflow_dispatch:

jobs:
  lighthouse-audit:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Setup database
        run: |
          npx prisma migrate deploy
          npx prisma generate
          npm run db:seed
      
      - name: Build application
        run: npm run build
      
      - name: Start application
        run: |
          npm run start &
          sleep 15
          curl -f http://localhost:3000/api/health
        env:
          NODE_ENV: production
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379
      
      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli@0.12.x
      
      - name: Run Lighthouse CI
        run: |
          lhci autorun \
            --config=./lighthouserc.js \
            --upload.target=temporary-public-storage \
            --collect.numberOfRuns=3 \
            --collect.settings.chromeFlags="--no-sandbox --headless"
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
      
      - name: Parse Lighthouse results
        run: |
          echo "## Lighthouse Performance Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Extract key metrics from Lighthouse results
          if [ -f ".lighthouseci/manifest.json" ]; then
            node -e "
              const manifest = require('./.lighthouseci/manifest.json');
              const results = manifest[0];
              if (results && results.summary) {
                console.log('### Performance Metrics');
                console.log('');
                Object.entries(results.summary).forEach(([key, value]) => {
                  if (typeof value === 'number') {
                    console.log(\`- **\${key}**: \${Math.round(value * 100)}/100\`);
                  }
                });
              }
            " >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Check performance thresholds
        run: |
          node scripts/check-performance-thresholds.js
        continue-on-error: true
      
      - name: Upload Lighthouse results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-results
          path: .lighthouseci/

  bundle-size-analysis:
    name: Bundle Size Analysis
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Generate Prisma client
        run: npx prisma generate
      
      - name: Build application
        run: npm run build
      
      - name: Analyze bundle size
        run: |
          npm install -g @next/bundle-analyzer
          
          echo "## Bundle Size Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Get bundle sizes
          du -h .next/static/chunks/* | head -20 >> bundle-sizes.txt
          
          echo "### Largest Chunks:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          head -10 bundle-sizes.txt >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          
          # Check for large bundles
          if find .next/static/chunks -name "*.js" -size +500k; then
            echo "⚠️ Large bundle files detected (>500KB)" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Bundle size regression check
        uses: andresz1/size-limit-action@v1
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          skip_step: install
      
      - name: Upload bundle analysis
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis
          path: |
            bundle-sizes.txt
            .next/analyze/

  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Setup test environment
        run: |
          npx prisma migrate deploy
          npx prisma generate
          npm run db:seed -- --size=large # Seed with more data for load testing
      
      - name: Build and start application
        run: |
          npm run build
          npm run start &
          sleep 20
        env:
          NODE_ENV: production
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379
      
      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
      
      - name: Run load tests
        run: |
          # API endpoint load tests
          k6 run tests/load/api-endpoints.js --out json=k6-api-results.json
          
          # User journey load tests
          k6 run tests/load/user-journeys.js --out json=k6-journey-results.json
          
          # Database performance tests
          k6 run tests/load/database-load.js --out json=k6-db-results.json
      
      - name: Analyze load test results
        run: |
          echo "## Load Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Parse k6 results
          node scripts/parse-k6-results.js k6-api-results.json >> $GITHUB_STEP_SUMMARY
          
          # Check performance thresholds
          if [ -f "k6-api-results.json" ]; then
            FAILED_CHECKS=$(jq '.metrics.checks.fails' k6-api-results.json)
            if [ "$FAILED_CHECKS" -gt 0 ]; then
              echo "❌ Load test performance thresholds failed" >> $GITHUB_STEP_SUMMARY
              exit 1
            else
              echo "✅ All performance thresholds passed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
      
      - name: Upload load test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: |
            k6-*.json
            load-test-report.html

  database-performance:
    name: Database Performance Analysis
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
          POSTGRES_INITDB_ARGS: "--auth-host=trust"
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Setup database with performance data
        run: |
          npx prisma migrate deploy
          npx prisma generate
          npm run db:seed -- --size=large --performance-test
      
      - name: Run database performance tests
        run: |
          echo "## Database Performance Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Run query performance analysis
          node scripts/db-performance-test.js
          
          # Check slow query log
          psql postgresql://postgres:postgres@localhost:5432/testdb -c "
            SELECT query, mean_exec_time, calls 
            FROM pg_stat_statements 
            WHERE mean_exec_time > 100 
            ORDER BY mean_exec_time DESC 
            LIMIT 10;
          " || echo "pg_stat_statements not available"
          
          # Analyze table sizes and index usage
          psql postgresql://postgres:postgres@localhost:5432/testdb -c "
            SELECT schemaname,tablename,attname,n_distinct,correlation 
            FROM pg_stats 
            WHERE schemaname = 'public' 
            ORDER BY tablename;
          "
      
      - name: Check database indexes
        run: |
          echo "### Index Usage Analysis" >> $GITHUB_STEP_SUMMARY
          
          # Check for missing indexes
          node scripts/check-missing-indexes.js >> $GITHUB_STEP_SUMMARY
          
          # Verify existing indexes are being used
          psql postgresql://postgres:postgres@localhost:5432/testdb -c "
            SELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch
            FROM pg_stat_user_indexes
            WHERE idx_scan = 0
            ORDER BY schemaname, tablename;
          " || echo "Index statistics not available"

  memory-profiling:
    name: Memory Profiling
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build application
        run: npm run build
      
      - name: Install memory profiling tools
        run: |
          npm install -g clinic
          npm install -g memwatch-next
      
      - name: Run memory profiling
        run: |
          # Start application with memory monitoring
          clinic doctor --name=memory-profile -- npm start &
          APP_PID=$!
          
          sleep 30
          
          # Simulate memory-intensive operations
          curl -X POST http://localhost:3000/api/gear -d '{"title":"Test"}' -H "Content-Type: application/json"
          
          # Let it run for analysis
          sleep 60
          
          kill $APP_PID
          
          # Generate memory report
          clinic doctor --analyze memory-profile.clinic-doctor
      
      - name: Check memory leaks
        run: |
          echo "## Memory Analysis Report" >> $GITHUB_STEP_SUMMARY
          
          if [ -d "memory-profile.clinic-doctor" ]; then
            echo "Memory profiling completed. Check artifacts for detailed analysis." >> $GITHUB_STEP_SUMMARY
          fi
          
          # Run heap snapshot analysis if available
          node scripts/memory-leak-detector.js || echo "Memory leak detector not available"
      
      - name: Upload memory profiling results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: memory-profiling
          path: |
            memory-profile.clinic-doctor/
            *.heapsnapshot

  create-performance-issue:
    name: Create Performance Issue
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, bundle-size-analysis, load-testing, database-performance]
    if: failure() && github.ref == 'refs/heads/main'
    
    steps:
      - name: Create performance issue
        uses: actions/github-script@v7
        with:
          script: |
            const title = `⚡ Performance Issue Detected - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            ## Performance Issue Report
            
            **Date:** ${new Date().toISOString()}
            **Commit:** ${context.sha}
            **Triggered by:** ${context.eventName}
            
            ### Issues Detected
            - Performance thresholds exceeded
            - Check workflow artifacts for detailed analysis
            
            ### Failed Jobs
            ${JSON.stringify(context.payload.workflow_run?.conclusion)}
            
            ### Recommended Actions
            1. Review Lighthouse performance report
            2. Analyze bundle size changes
            3. Check database query performance
            4. Review load testing results
            5. Optimize identified bottlenecks
            
            ### Performance Targets
            - Lighthouse Performance: >90
            - First Contentful Paint: <1.5s
            - Largest Contentful Paint: <2.5s
            - Cumulative Layout Shift: <0.1
            - Time to Interactive: <3.5s
            
            **Priority:** High
            **Labels:** performance, optimization
            `;
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['performance', 'optimization', 'high-priority']
            });

  performance-dashboard-update:
    name: Update Performance Dashboard
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, bundle-size-analysis, load-testing]
    if: always() && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Update performance metrics
        run: |
          # This would update a performance tracking system
          # Could be DataDog, New Relic, or custom dashboard
          echo "Updating performance dashboard with latest metrics..."
          
          # Send metrics to monitoring service
          curl -X POST "${{ secrets.PERFORMANCE_WEBHOOK_URL }}" \
            -H "Content-Type: application/json" \
            -d '{
              "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
              "commit": "'${{ github.sha }}'",
              "branch": "'${{ github.ref_name }}'",
              "lighthouse_score": "'$LIGHTHOUSE_SCORE'",
              "bundle_size": "'$BUNDLE_SIZE'",
              "load_test_p95": "'$LOAD_TEST_P95'"
            }' || echo "Failed to update dashboard"
        env:
          LIGHTHOUSE_SCORE: 85 # Would be extracted from actual results
          BUNDLE_SIZE: "2.1MB" # Would be extracted from actual results
          LOAD_TEST_P95: "250ms" # Would be extracted from actual results